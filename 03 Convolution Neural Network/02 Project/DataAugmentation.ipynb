{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataset Directories\n",
    "\n",
    "trainDir = 'datasets/train/'\n",
    "testDir = 'datasets/test/'\n",
    "valDir = 'datasets/validation/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "### Converting Image Data to Tensors\n",
    "\n",
    "trainDataGen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "testDataGen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "trainGenerator = trainDataGen.flow_from_directory(\n",
    "    trainDir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "valGenerator = testDataGen.flow_from_directory(\n",
    "    valDir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "# 4 Convolution layers with maxpooling\n",
    "model.add(layers.Conv2D(32, (3, 3), activation = 'relu', input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten Layer\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Dropout Layer\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Dense Layer\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "\n",
    "# Output Dense Layer\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6720 - acc: 0.5852WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 104s 2s/step - loss: 0.6720 - acc: 0.5852 - val_loss: 0.6476 - val_acc: 0.6430\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6636 - acc: 0.5969WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 109s 2s/step - loss: 0.6636 - acc: 0.5969 - val_loss: 0.6447 - val_acc: 0.6430\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6505 - acc: 0.6256WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 77s 2s/step - loss: 0.6505 - acc: 0.6256 - val_loss: 0.6273 - val_acc: 0.6540\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6455 - acc: 0.6181WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 79s 2s/step - loss: 0.6455 - acc: 0.6181 - val_loss: 0.6734 - val_acc: 0.5750\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6303 - acc: 0.6381WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 84s 2s/step - loss: 0.6303 - acc: 0.6381 - val_loss: 0.6157 - val_acc: 0.6460\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6351 - acc: 0.6275WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 79s 2s/step - loss: 0.6351 - acc: 0.6275 - val_loss: 0.6124 - val_acc: 0.6530\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6138 - acc: 0.6622WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 77s 2s/step - loss: 0.6138 - acc: 0.6622 - val_loss: 0.5868 - val_acc: 0.6930\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6247 - acc: 0.6534WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 82s 2s/step - loss: 0.6247 - acc: 0.6534 - val_loss: 0.5899 - val_acc: 0.6750\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6152 - acc: 0.6648WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 84s 2s/step - loss: 0.6152 - acc: 0.6648 - val_loss: 0.5807 - val_acc: 0.6970\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5995 - acc: 0.6768WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 87s 2s/step - loss: 0.5995 - acc: 0.6768 - val_loss: 0.5862 - val_acc: 0.6880\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6128 - acc: 0.6481WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 84s 2s/step - loss: 0.6128 - acc: 0.6481 - val_loss: 0.5856 - val_acc: 0.6820\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5991 - acc: 0.6793WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 78s 2s/step - loss: 0.5991 - acc: 0.6793 - val_loss: 0.5693 - val_acc: 0.6930\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6053 - acc: 0.6648WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 80s 2s/step - loss: 0.6053 - acc: 0.6648 - val_loss: 0.5794 - val_acc: 0.6800\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5975 - acc: 0.6862WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 77s 2s/step - loss: 0.5975 - acc: 0.6862 - val_loss: 0.5533 - val_acc: 0.7160\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5950 - acc: 0.6736WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 85s 2s/step - loss: 0.5950 - acc: 0.6736 - val_loss: 0.5517 - val_acc: 0.7050\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5829 - acc: 0.6875WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 96s 2s/step - loss: 0.5829 - acc: 0.6875 - val_loss: 0.5529 - val_acc: 0.7160\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5889 - acc: 0.6742WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 89s 2s/step - loss: 0.5889 - acc: 0.6742 - val_loss: 0.5552 - val_acc: 0.7040\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5786 - acc: 0.7027WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 77s 2s/step - loss: 0.5786 - acc: 0.7027 - val_loss: 0.5524 - val_acc: 0.7140\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5753 - acc: 0.6907WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 75s 1s/step - loss: 0.5753 - acc: 0.6907 - val_loss: 0.5294 - val_acc: 0.7170\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5761 - acc: 0.7090WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 80s 2s/step - loss: 0.5761 - acc: 0.7090 - val_loss: 0.5953 - val_acc: 0.6750\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5643 - acc: 0.7052WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 75s 1s/step - loss: 0.5643 - acc: 0.7052 - val_loss: 0.5323 - val_acc: 0.7230\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5633 - acc: 0.7159WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 75s 1s/step - loss: 0.5633 - acc: 0.7159 - val_loss: 0.5228 - val_acc: 0.7330\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5770 - acc: 0.7039WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 75s 1s/step - loss: 0.5770 - acc: 0.7039 - val_loss: 0.5250 - val_acc: 0.7410\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5625 - acc: 0.7064WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 77s 2s/step - loss: 0.5625 - acc: 0.7064 - val_loss: 0.5248 - val_acc: 0.7230\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5622 - acc: 0.7038WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 79s 2s/step - loss: 0.5622 - acc: 0.7038 - val_loss: 0.5259 - val_acc: 0.7260\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5597 - acc: 0.7071WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 79s 2s/step - loss: 0.5597 - acc: 0.7071 - val_loss: 0.5262 - val_acc: 0.7260\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5585 - acc: 0.7191WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.5585 - acc: 0.7191 - val_loss: 0.5226 - val_acc: 0.7300\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5515 - acc: 0.7159WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 75s 2s/step - loss: 0.5515 - acc: 0.7159 - val_loss: 0.5376 - val_acc: 0.7180\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5503 - acc: 0.7210WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 75s 1s/step - loss: 0.5503 - acc: 0.7210 - val_loss: 0.5496 - val_acc: 0.7160\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5583 - acc: 0.7138WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 77s 2s/step - loss: 0.5583 - acc: 0.7138 - val_loss: 0.5375 - val_acc: 0.7170\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5462 - acc: 0.7156WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.5462 - acc: 0.7156 - val_loss: 0.5123 - val_acc: 0.7370\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5408 - acc: 0.7424WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 75s 1s/step - loss: 0.5408 - acc: 0.7424 - val_loss: 0.5093 - val_acc: 0.7330\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5521 - acc: 0.7115WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 75s 2s/step - loss: 0.5521 - acc: 0.7115 - val_loss: 0.5197 - val_acc: 0.7250\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5292 - acc: 0.7294WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.5292 - acc: 0.7294 - val_loss: 0.4829 - val_acc: 0.7520\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5413 - acc: 0.7254WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 75s 2s/step - loss: 0.5413 - acc: 0.7254 - val_loss: 0.5808 - val_acc: 0.6830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5230 - acc: 0.7449WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.5230 - acc: 0.7449 - val_loss: 0.5191 - val_acc: 0.7320\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5371 - acc: 0.7197WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 75s 2s/step - loss: 0.5371 - acc: 0.7197 - val_loss: 0.5181 - val_acc: 0.7250\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5283 - acc: 0.7462WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 75s 2s/step - loss: 0.5283 - acc: 0.7462 - val_loss: 0.5051 - val_acc: 0.7470\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5274 - acc: 0.7449WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 75s 1s/step - loss: 0.5274 - acc: 0.7449 - val_loss: 0.4850 - val_acc: 0.7520\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5387 - acc: 0.7348WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.5387 - acc: 0.7348 - val_loss: 0.5240 - val_acc: 0.7250\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5083 - acc: 0.7538WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.5083 - acc: 0.7538 - val_loss: 0.4840 - val_acc: 0.7520\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5277 - acc: 0.7418WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.5277 - acc: 0.7418 - val_loss: 0.5832 - val_acc: 0.6950\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5107 - acc: 0.7462WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 75s 2s/step - loss: 0.5107 - acc: 0.7462 - val_loss: 0.4827 - val_acc: 0.7600\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5228 - acc: 0.7375WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.5228 - acc: 0.7375 - val_loss: 0.4890 - val_acc: 0.7560\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5103 - acc: 0.7475WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 75s 1s/step - loss: 0.5103 - acc: 0.7475 - val_loss: 0.5129 - val_acc: 0.7310\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5084 - acc: 0.7557WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 75s 2s/step - loss: 0.5084 - acc: 0.7557 - val_loss: 0.5465 - val_acc: 0.7230\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5110 - acc: 0.7381WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 77s 2s/step - loss: 0.5110 - acc: 0.7381 - val_loss: 0.5210 - val_acc: 0.7390\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4966 - acc: 0.7544WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 91s 2s/step - loss: 0.4966 - acc: 0.7544 - val_loss: 0.4894 - val_acc: 0.7530\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4977 - acc: 0.7576WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 87s 2s/step - loss: 0.4977 - acc: 0.7576 - val_loss: 0.5309 - val_acc: 0.7260\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5003 - acc: 0.7462WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 79s 2s/step - loss: 0.5003 - acc: 0.7462 - val_loss: 0.5268 - val_acc: 0.7360\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4840 - acc: 0.7606WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 81s 2s/step - loss: 0.4840 - acc: 0.7606 - val_loss: 0.4805 - val_acc: 0.7650\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5061 - acc: 0.7614WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 80s 2s/step - loss: 0.5061 - acc: 0.7614 - val_loss: 0.4911 - val_acc: 0.7580\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5045 - acc: 0.7538WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 78s 2s/step - loss: 0.5045 - acc: 0.7538 - val_loss: 0.6014 - val_acc: 0.6900\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5008 - acc: 0.7645WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 79s 2s/step - loss: 0.5008 - acc: 0.7645 - val_loss: 0.5266 - val_acc: 0.7270\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4811 - acc: 0.7631WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 80s 2s/step - loss: 0.4811 - acc: 0.7631 - val_loss: 0.4705 - val_acc: 0.7680\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5048 - acc: 0.7576WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 79s 2s/step - loss: 0.5048 - acc: 0.7576 - val_loss: 0.4810 - val_acc: 0.7620\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4999 - acc: 0.7481WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 79s 2s/step - loss: 0.4999 - acc: 0.7481 - val_loss: 0.5042 - val_acc: 0.7530\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5029 - acc: 0.7645WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 79s 2s/step - loss: 0.5029 - acc: 0.7645 - val_loss: 0.4958 - val_acc: 0.7540\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4864 - acc: 0.7550WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 80s 2s/step - loss: 0.4864 - acc: 0.7550 - val_loss: 0.5416 - val_acc: 0.7350\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4871 - acc: 0.7719WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 79s 2s/step - loss: 0.4871 - acc: 0.7719 - val_loss: 0.4653 - val_acc: 0.7800\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4691 - acc: 0.7784WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 79s 2s/step - loss: 0.4691 - acc: 0.7784 - val_loss: 0.4467 - val_acc: 0.7880\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4802 - acc: 0.7531WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 91s 2s/step - loss: 0.4802 - acc: 0.7531 - val_loss: 0.5026 - val_acc: 0.7470\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4929 - acc: 0.7633WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 95s 2s/step - loss: 0.4929 - acc: 0.7633 - val_loss: 0.4867 - val_acc: 0.7650\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4679 - acc: 0.7694WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 83s 2s/step - loss: 0.4679 - acc: 0.7694 - val_loss: 0.6565 - val_acc: 0.6750\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4914 - acc: 0.7600WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 78s 2s/step - loss: 0.4914 - acc: 0.7600 - val_loss: 0.5057 - val_acc: 0.7510\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4745 - acc: 0.7753WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 79s 2s/step - loss: 0.4745 - acc: 0.7753 - val_loss: 0.4496 - val_acc: 0.7850\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4733 - acc: 0.7677WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 79s 2s/step - loss: 0.4733 - acc: 0.7677 - val_loss: 0.5381 - val_acc: 0.7440\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4896 - acc: 0.7631WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 80s 2s/step - loss: 0.4896 - acc: 0.7631 - val_loss: 0.4772 - val_acc: 0.7690\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4690 - acc: 0.7837WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 80s 2s/step - loss: 0.4690 - acc: 0.7837 - val_loss: 0.4639 - val_acc: 0.7810\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4745 - acc: 0.7753WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 78s 2s/step - loss: 0.4745 - acc: 0.7753 - val_loss: 0.4895 - val_acc: 0.7610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4838 - acc: 0.7708WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 79s 2s/step - loss: 0.4838 - acc: 0.7708 - val_loss: 0.4350 - val_acc: 0.7920\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4694 - acc: 0.7803WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 91s 2s/step - loss: 0.4694 - acc: 0.7803 - val_loss: 0.4499 - val_acc: 0.7760\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4661 - acc: 0.7727WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 77s 2s/step - loss: 0.4661 - acc: 0.7727 - val_loss: 0.4322 - val_acc: 0.7970\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4711 - acc: 0.7670WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 79s 2s/step - loss: 0.4711 - acc: 0.7670 - val_loss: 0.4792 - val_acc: 0.7640\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4610 - acc: 0.7828WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.4610 - acc: 0.7828 - val_loss: 0.4654 - val_acc: 0.7740\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4759 - acc: 0.7828WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.4759 - acc: 0.7828 - val_loss: 0.4977 - val_acc: 0.7570\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4763 - acc: 0.7708WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.4763 - acc: 0.7708 - val_loss: 0.4937 - val_acc: 0.7500\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4569 - acc: 0.7778WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.4569 - acc: 0.7778 - val_loss: 0.5056 - val_acc: 0.7510\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4561 - acc: 0.7831WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.4561 - acc: 0.7831 - val_loss: 0.4265 - val_acc: 0.7990\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4558 - acc: 0.7778WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.4558 - acc: 0.7778 - val_loss: 0.4544 - val_acc: 0.7810\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4676 - acc: 0.7828WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.4676 - acc: 0.7828 - val_loss: 0.4335 - val_acc: 0.7950\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4645 - acc: 0.7790WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.4645 - acc: 0.7790 - val_loss: 0.4824 - val_acc: 0.7660\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4457 - acc: 0.7986WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 77s 2s/step - loss: 0.4457 - acc: 0.7986 - val_loss: 0.4295 - val_acc: 0.8010\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4521 - acc: 0.7753WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.4521 - acc: 0.7753 - val_loss: 0.4310 - val_acc: 0.8020\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4541 - acc: 0.7931WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.4541 - acc: 0.7931 - val_loss: 0.4552 - val_acc: 0.7800\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4236 - acc: 0.8068WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 77s 2s/step - loss: 0.4236 - acc: 0.8068 - val_loss: 0.4802 - val_acc: 0.7630\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4499 - acc: 0.7961WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.4499 - acc: 0.7961 - val_loss: 0.4552 - val_acc: 0.7810\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4419 - acc: 0.7923WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 77s 2s/step - loss: 0.4419 - acc: 0.7923 - val_loss: 0.4474 - val_acc: 0.7800\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4514 - acc: 0.7898WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.4514 - acc: 0.7898 - val_loss: 0.4370 - val_acc: 0.7950\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4529 - acc: 0.7822WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.4529 - acc: 0.7822 - val_loss: 0.5396 - val_acc: 0.7180\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4448 - acc: 0.7962WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.4448 - acc: 0.7962 - val_loss: 0.4382 - val_acc: 0.7970\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4436 - acc: 0.7967WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 75s 2s/step - loss: 0.4436 - acc: 0.7967 - val_loss: 0.4615 - val_acc: 0.7880\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4446 - acc: 0.7923WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.4446 - acc: 0.7923 - val_loss: 0.4345 - val_acc: 0.8120\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4471 - acc: 0.7973WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 77s 2s/step - loss: 0.4471 - acc: 0.7973 - val_loss: 0.4688 - val_acc: 0.7870\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4541 - acc: 0.7835WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.4541 - acc: 0.7835 - val_loss: 0.5000 - val_acc: 0.7720\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4429 - acc: 0.7898WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.4429 - acc: 0.7898 - val_loss: 0.4372 - val_acc: 0.7950\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4474 - acc: 0.7828WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.4474 - acc: 0.7828 - val_loss: 0.4426 - val_acc: 0.7930\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4350 - acc: 0.7973WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.4350 - acc: 0.7973 - val_loss: 0.4724 - val_acc: 0.7720\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4533 - acc: 0.7809WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.4533 - acc: 0.7809 - val_loss: 0.4638 - val_acc: 0.7850\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4362 - acc: 0.8056WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.4362 - acc: 0.8056 - val_loss: 0.4346 - val_acc: 0.7970\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'repeat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-25fe0a32b339>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtrainGenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalGenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'History' object has no attribute 'repeat'"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    trainGenerator,\n",
    "    steps_per_epoch=50,\n",
    "    epochs=100,\n",
    "    validation_data=valGenerator,\n",
    "    validation_steps=50\n",
    ").repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"DataAugmentation.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
